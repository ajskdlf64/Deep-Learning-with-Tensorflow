{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple Linear Regression 를 TensorFlow 로 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(x) = W(x) + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "\n",
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "# Hypothesis : y = Wx + b\n",
    "hypothesis = W * x_data + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W,b) = {1 \\over m} \\sum_{i=1}^{m}(H(x^{(i)}) - y^{(i)})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=31, shape=(), dtype=float32, numpy=2.5>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = [1., 2., 3., 4.]\n",
    "tf.reduce_mean(v)   # 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.square()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=34, shape=(), dtype=int32, numpy=9>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(3)   # 9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$minimize\\;cost(W,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "A.assign_sub(B)\n",
    "A = A - B\n",
    "A -= B\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = 2.4520, b = 0.3760\n"
     ]
    }
   ],
   "source": [
    "# learning_rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Gradient Descent\n",
    "with tf.GradientTape() as tape : \n",
    "    hypothesis = W * x_data + b\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "W_grad, b_grad = tape.gradient(cost, [W,b])\n",
    "\n",
    "W.assign_sub(learning_rate * W_grad)\n",
    "b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "print('W = {:.4f}, b = {:.4f}' .format(W.numpy(),b.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Parameter Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  i  |W.numpy() |b.numpy() |   cost   \n",
      "  0  |  2.452   |  0.376   |45.660004 \n",
      " 10  |  1.104   | 0.003398 | 0.206336 \n",
      " 20  |  1.013   | -0.02091 | 0.001026 \n",
      " 30  |  1.007   | -0.02184 | 0.000093 \n",
      " 40  |  1.006   | -0.02123 | 0.000083 \n",
      " 50  |  1.006   | -0.02053 | 0.000077 \n",
      " 60  |  1.005   | -0.01984 | 0.000072 \n",
      " 70  |  1.005   | -0.01918 | 0.000067 \n",
      " 80  |  1.005   | -0.01854 | 0.000063 \n",
      " 90  |  1.005   | -0.01793 | 0.000059 \n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "print('{:^5}|{:^10}|{:^10}|{:^10}' .format('i', 'W.numpy()', 'b.numpy()', 'cost'))\n",
    "\n",
    "for i in range(100) :\n",
    "    \n",
    "    with tf.GradientTape() as tape : \n",
    "        hypothesis = W * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "        \n",
    "    W_grad, b_grad = tape.gradient(cost, [W,b])\n",
    "    \n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 10 == 0 : \n",
    "        print('{:^5}|{:^10.4}|{:^10.4}|{:^10.6f}' .format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(x) = Wx + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.0066934, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9970603, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(W * 5.0 + b)\n",
    "print(W * 3.0 + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear Regression and How to minimize cost 를 TensorFlow 로 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function in pure python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W) = {1 \\over m} \\sum_{i=1}^{m}(W(x_{i}) - y_{i})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,2,3])\n",
    "\n",
    "def cost_fnc(W,X,Y) : \n",
    "    c = 0\n",
    "    for i in range(len(X)) : \n",
    "        c += (W * X[i] - Y[i])**2\n",
    "    return c / len(X)\n",
    "\n",
    "for feed_W in np.linspace(-3, 5, num=15) :\n",
    "    curr_cost = cost_fnc(feed_W, X, Y)\n",
    "    print(\"{:6.3f} | {:10.5f}\" .format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost function in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([1,2,3])\n",
    "Y = np.array([1,2,3])\n",
    "\n",
    "def cost_fnc(W,X,Y) : \n",
    "    hypothesis = X * W\n",
    "    return tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "for feed_W in np.linspace(-3, 5, num=15) :\n",
    "    curr_cost = cost_fnc(feed_W, X, Y)\n",
    "    print(\"{:6.3f} | {:10.5f}\" .format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.00022470951>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "gradient = tf.reduce_mean(tf.multiply(tf.multiply(W,X) - Y, X))\n",
    "descent = W - tf.multiply(alpha, gradient)\n",
    "W.assign_sub(descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0| 1397.7949| -0.807653\n",
      "   10|    5.1347| -0.048951\n",
      "   20|    5.1347| -0.048951\n",
      "   30|    5.1347| -0.048951\n",
      "   40|    5.1347| -0.048951\n",
      "   50|    5.1347| -0.048951\n",
      "   60|    5.1347| -0.048951\n",
      "   70|    5.1347| -0.048951\n",
      "   80|    5.1347| -0.048951\n",
      "   90|    5.1347| -0.048951\n",
      "  100|    5.1347| -0.048951\n",
      "  110|    5.1347| -0.048951\n",
      "  120|    5.1347| -0.048951\n",
      "  130|    5.1347| -0.048951\n",
      "  140|    5.1347| -0.048951\n",
      "  150|    5.1347| -0.048951\n",
      "  160|    5.1347| -0.048951\n",
      "  170|    5.1347| -0.048951\n",
      "  180|    5.1347| -0.048951\n",
      "  190|    5.1347| -0.048951\n",
      "  200|    5.1347| -0.048951\n",
      "  210|    5.1347| -0.048951\n",
      "  220|    5.1347| -0.048951\n",
      "  230|    5.1347| -0.048951\n",
      "  240|    5.1347| -0.048951\n",
      "  250|    5.1347| -0.048951\n",
      "  260|    5.1347| -0.048951\n",
      "  270|    5.1347| -0.048951\n",
      "  280|    5.1347| -0.048951\n",
      "  290|    5.1347| -0.048951\n"
     ]
    }
   ],
   "source": [
    "# seed\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "# data\n",
    "x_data = [1., 2., 3., 4.]\n",
    "y_data = [1., 3., 5., 7.]\n",
    "\n",
    "# weight\n",
    "W = tf.Variable(tf.random_normal([1], -100, 100))\n",
    "\n",
    "# Gradient Descent\n",
    "for step in range(300) : \n",
    "    hypothesis = W * X\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    \n",
    "    alpha = 0.01\n",
    "    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W,X) - Y, X))\n",
    "    descent = W - tf.multiply(alpha, gradient)\n",
    "    W.assign_sub(descent)\n",
    "    \n",
    "    if step % 10 == 0 : \n",
    "        print('{:5}|{:10.4f}|{:10.6f}' .format(step,cost.numpy(),W.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-variable Linear Regression 를 TensorFlow 로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |     551.4631\n",
      "   50 |       9.5045\n",
      "  100 |       3.4850\n",
      "  150 |       3.4123\n",
      "  200 |       3.4056\n",
      "  250 |       3.3996\n",
      "  300 |       3.3936\n",
      "  350 |       3.3877\n",
      "  400 |       3.3818\n",
      "  450 |       3.3759\n",
      "  500 |       3.3700\n",
      "  550 |       3.3641\n",
      "  600 |       3.3582\n",
      "  650 |       3.3523\n",
      "  700 |       3.3465\n",
      "  750 |       3.3406\n",
      "  800 |       3.3347\n",
      "  850 |       3.3290\n",
      "  900 |       3.3232\n",
      "  950 |       3.3175\n",
      " 1000 |       3.3117\n"
     ]
    }
   ],
   "source": [
    "# data and label\n",
    "x1 = [73., 93., 89., 96., 73]\n",
    "x2 = [80., 88., 91., 98., 66]\n",
    "x3 = [75., 93., 90., 100., 70]\n",
    "Y = [152., 185., 180., 196., 142]\n",
    "\n",
    "# random weights\n",
    "w1 = tf.Variable(tf.random_normal([1]))\n",
    "w2 = tf.Variable(tf.random_normal([1]))\n",
    "w3 = tf.Variable(tf.random_normal([1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# Multi-Variable-Linear-Regression\n",
    "for i in range(1001) : \n",
    "    \n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape : \n",
    "        hypothesis = w1*x1 + w2*x2 + w3*x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1,w2,w3,b])\n",
    "    \n",
    "    # update w1,w2,w3 and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    # process print\n",
    "    if i % 50 == 0 : \n",
    "        print(\"{:5} | {:12.4f}\" .format(i,cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(X) = XW$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X \n",
      " [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]] \n",
      "\n",
      "y \n",
      " [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]] \n",
      "\n",
      "W \n",
      " [[-0.3198804 ]\n",
      " [ 1.3575249 ]\n",
      " [-0.15776916]] \n",
      "\n",
      "b \n",
      " [0.80348307] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[73.,  80.,  75.,  152.],\n",
    "                 [93.,  88.,  93.,  185.],\n",
    "                 [89.,  91.,  90.,  180.],\n",
    "                 [96.,  98., 100.,  196.],\n",
    "                 [73.,  66.,  70.,  142.]], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "X = data[:, :-1]\n",
    "print('X','\\n',X,'\\n')\n",
    "y = data[:, [-1]]\n",
    "print('y','\\n',y,'\\n')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]))\n",
    "print('W','\\n',W.numpy(),'\\n')\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "print('b','\\n',b.numpy(),'\\n')\n",
    "\n",
    "def predict(X) :\n",
    "    return tf.matmul(X,W) + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
